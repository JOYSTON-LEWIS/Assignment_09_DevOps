pipeline {
    agent any

    environment {
        // AWS & Infra Credentials
        JL_AWS_REGION_ID                = credentials('JL_AWS_REGION_ID')
        JL_AWS_OUTPUT_FORMAT            = 'json'
        JL_AS09_EC2_IP_ADDRESS          = credentials('JL_AS09_EC2_IP_ADDRESS')
        JL_EC2_SSH_PRIVATE_KEY          = credentials('JL_EC2_SSH_PRIVATE_KEY')

        // App & GitHub
        JL_AS09_S3_BACKUP_BUCKET_NAME   = credentials('JL_AS09_S3_BACKUP_BUCKET_NAME')
        JL_AS09_LAMBDA_ROLE_ARN         = credentials('JL_AS09_LAMBDA_ROLE_ARN')
        JL_AS09_MONGO_URI_WITH_DB_NAME  = credentials('JL_AS09_MONGO_URI_WITH_DB_NAME')
        JL_AS09_GITHUB_REPO_URL         = credentials('JL_AS09_GITHUB_REPO_URL')
    }

    stages {

        stage('Step 1: Install All Tools on EC2') {
            steps {
                withCredentials([[
                    $class: 'AmazonWebServicesCredentialsBinding',
                    credentialsId: 'JL_AWS_CREDENTIALS',
                    accessKeyVariable: 'AWS_ACCESS_KEY_ID',
                    secretKeyVariable: 'AWS_SECRET_ACCESS_KEY'
                ]]) {
                    sshagent (credentials: ['JL_EC2_SSH_PRIVATE_KEY']) {
                        script {
                            def SSH_IP = env.JL_AS09_EC2_IP_ADDRESS
                            def REGION = env.JL_AWS_REGION_ID
                            def OUTPUT = env.JL_AWS_OUTPUT_FORMAT
                            def ACCESS_KEY = AWS_ACCESS_KEY_ID
                            def SECRET_KEY = AWS_SECRET_ACCESS_KEY

                            sh """
                            ssh -o StrictHostKeyChecking=no ubuntu@${SSH_IP} << EOF
echo "‚úÖ Connected to EC2"

# Update system and install packages
sudo apt-get update -y
sudo apt-get upgrade -y
sudo apt-get install -y docker.io curl git apt-transport-https software-properties-common conntrack daemonize python3 python3-pip unzip jq

# Add ubuntu to docker group
sudo usermod -aG docker ubuntu

# Fix kernel file protection
sudo sysctl fs.protected_regular=0

# Install kubectl
curl -LO https://dl.k8s.io/release/v1.33.1/bin/linux/amd64/kubectl
chmod +x kubectl && sudo mv kubectl /usr/local/bin/

# Install Minikube
curl -Lo minikube https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
chmod +x minikube && sudo mv minikube /usr/local/bin/

# Install Helm
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash

# Clean previous Minikube setup
minikube delete --all --purge || true
rm -rf ~/.minikube ~/.kube

# Configure containerd
cat <<EOF2 | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF2
sudo modprobe overlay
sudo modprobe br_netfilter

cat <<EOF3 | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF3
sudo sysctl --system

# Install and enable containerd
sudo apt-get install -y containerd
sudo mkdir -p /etc/containerd
sudo containerd config default | sudo tee /etc/containerd/config.toml
sudo sed -i 's/SystemdCgroup = false/SystemdCgroup = true/' /etc/containerd/config.toml
sudo systemctl enable --now containerd

# Install crictl
VERSION="v1.33.1"
wget https://github.com/kubernetes-sigs/cri-tools/releases/download/\$VERSION/crictl-\$VERSION-linux-amd64.tar.gz
tar --overwrite -xvzf crictl-\$VERSION-linux-amd64.tar.gz
sudo install crictl /usr/local/bin/

# Install CNI plugins
wget https://github.com/containernetworking/plugins/releases/download/v1.5.0/cni-plugins-linux-amd64-v1.5.0.tgz
sudo mkdir -p /opt/cni/bin
sudo tar --overwrite -xvzf cni-plugins-linux-amd64-v1.5.0.tgz -C /opt/cni/bin/

# Start Minikube with containerd (no driver)
sudo CHANGE_MINIKUBE_NONE_USER=true minikube start --driver=none --container-runtime=containerd

# Install boto3
pip3 install --upgrade boto3 --break-system-packages

# AWS CLI
rm -rf aws awscliv2.zip
curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"
unzip -o awscliv2.zip
sudo ./aws/install

# Configure AWS CLI
aws configure set aws_access_key_id "${ACCESS_KEY}"
aws configure set aws_secret_access_key "${SECRET_KEY}"
aws configure set region "${REGION}"
aws configure set output "${OUTPUT}"

echo "‚úÖ AWS credentials configured inside EC2"

rm -rf aws awscliv2.zip crictl-*.tar.gz cni-plugins-*.tgz cni-plugins-*.tgz.* crictl-*.tar.gz.*

EOF
                        """
                        }
                    }
                }
            }
        }

        stage('Step 2: Clone GitHub Repo on EC2') {
            steps {
                sshagent (credentials: ['JL_EC2_SSH_PRIVATE_KEY']) {
                    script {
                        def SSH_IP = env.JL_AS09_EC2_IP_ADDRESS
                        def GIT_REPO = env.JL_AS09_GITHUB_REPO_URL
                        def repoName = GIT_REPO.split('/').last().replace('.git', '')

                        sh """
                        ssh -o StrictHostKeyChecking=no ubuntu@${SSH_IP} << EOF
mkdir -p ~/assignment09 && cd ~/assignment09
rm -rf ${repoName}
git clone ${GIT_REPO}
echo "‚úÖ Repo cloned to ~/assignment09/${repoName}"
EOF
                        """
                    }
                }
            }
        }

        stage('Step 3: Verify Repo Folder Structure & Validate Tools') {
            steps {
                sshagent (credentials: ['JL_EC2_SSH_PRIVATE_KEY']) {
                    script {
                        def SSH_IP = env.JL_AS09_EC2_IP_ADDRESS
                        def GIT_REPO = env.JL_AS09_GITHUB_REPO_URL
                        def repoName = GIT_REPO.split('/').last().replace('.git', '')
                        def REMOTE_DIR = "~/assignment09/${repoName}"

                        sh """
ssh -o StrictHostKeyChecking=no ubuntu@${SSH_IP} << EOF
set -e
cd ${REMOTE_DIR}

echo "üìÅ Verifying project structure..."
if [ ! -d "frontend" ] || [ ! -d "backend/helloService" ] || [ ! -d "backend/profileService" ]; then
    echo "‚ùå ERROR: Required folders missing!"
    exit 1
fi

echo "‚úÖ Folder structure is valid: frontend/, backend/helloService/, backend/profileService/"

echo "üîç Running validations for installed tools..."

# Docker
docker --version
sudo systemctl is-active docker

# Containerd
containerd --version
sudo systemctl is-active containerd

# Kubernetes
kubectl version --client=true --output=yaml
minikube version
crictl --version

# CNI
ls /opt/cni/bin | wc -l

# Helm
helm version

# Python & boto3
python3 --version
pip3 --version
pip3 show boto3

# Kernel modules and sysctl
lsmod | grep br_netfilter
lsmod | grep overlay

sysctl net.bridge.bridge-nf-call-iptables
sysctl net.ipv4.ip_forward

# Docker group membership
groups ubuntu | grep -qw docker || echo "‚ùå 'ubuntu' user not in docker group"

# AWS CLI version check
aws --version

# AWS identity check (verifies credentials are configured)
aws sts get-caller-identity || echo "‚ùå AWS CLI is not configured correctly"

echo "‚úÖ Tool validation complete"
EOF
                        """
                    }
                }
            }
        }

stage('Step 4: Dockerize and Push to ECR') {
    steps {
        sshagent (credentials: ['JL_EC2_SSH_PRIVATE_KEY']) {
            script {
                def SSH_IP = env.JL_AS09_EC2_IP_ADDRESS
                def GIT_REPO = env.JL_AS09_GITHUB_REPO_URL
                def repoName = GIT_REPO.split('/').last().replace('.git', '')
                def REMOTE_DIR = "~/assignment09/${repoName}"
                def MONGO_URI = env.JL_AS09_MONGO_URI_WITH_DB_NAME
                def AWS_REGION = env.JL_AWS_REGION_ID

                sh """
                ssh -o StrictHostKeyChecking=no ubuntu@${SSH_IP} << 'EOF'
set -e
cd ${REMOTE_DIR}

echo "üßπ Removing old Docker images..."
docker rmi -f \$(docker images -q) || true

echo "üì¶ Creating .env files..."
cat <<EOT > backend/helloService/.env
PORT=3001
EOT

cat <<EOT > backend/profileService/.env
PORT=3002
MONGO_URL=${MONGO_URI}
EOT

cat <<EOT > frontend/.env
REACT_APP_HELLO_BASE_URL=http://hello-service:3001
REACT_APP_PROFILE_BASE_URL=http://profile-service:3002
EOT

echo "üê≥ Creating Dockerfiles..."
cat <<EOT > backend/helloService/Dockerfile
FROM node:20.9.0-alpine
WORKDIR /app
COPY . .
RUN npm install
EXPOSE 3001
CMD ["node", "index.js"]
EOT

cat <<EOT > backend/profileService/Dockerfile
FROM node:20.9.0-alpine
WORKDIR /app
COPY . .
RUN npm install
EXPOSE 3002
CMD ["node", "index.js"]
EOT

cat <<EOT > frontend/Dockerfile
FROM node:20.9.0-alpine
WORKDIR /app
COPY . .
RUN npm install && npm run build
RUN npm install -g serve
EXPOSE 3000
CMD ["serve", "-s", "build", "-l", "3000"]
EOT

echo "‚¨áÔ∏è Pulling base image to avoid Docker Hub login..."
docker pull node:20.9.0-alpine

echo "üßπ Removing stale Docker Hub credentials..."
sudo rm -f ~/.docker/config.json

ACCOUNT_ID=\$(aws sts get-caller-identity --query Account --output text)
ECR_BASE="\${ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com"

for SERVICE in hello-service profile-service frontend; do
  REPO_NAME="jl-assignment-nine-\$SERVICE"
  IMAGE_TAG="\$REPO_NAME"

  echo "üìÅ Ensuring ECR repository '\$REPO_NAME' exists..."
  aws ecr describe-repositories --repository-names \$REPO_NAME || \
  aws ecr create-repository --repository-name \$REPO_NAME

  echo "üîê Logging into ECR..."
  aws ecr get-login-password --region ${AWS_REGION} | docker login --username AWS --password-stdin \$ECR_BASE

  echo "üì§ Building and pushing \$SERVICE image..."
  
  if [ "\$SERVICE" = "frontend" ]; then
    cd frontend
  elif [ "\$SERVICE" = "hello-service" ]; then
    cd backend/helloService
  elif [ "\$SERVICE" = "profile-service" ]; then
    cd backend/profileService
  fi

  docker build -t \$IMAGE_TAG .
  docker tag \$IMAGE_TAG \$ECR_BASE/\$REPO_NAME
  docker push \$ECR_BASE/\$REPO_NAME
  cd -
done

echo "‚úÖ All images built and pushed to ECR repositories successfully."
EOF
                """
            }
        }
    }
}









    }
}
